version: '3.2'
services:
    postgres:
        image: postgres:9.6
        environment:
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow

    webserver:
        build: .
        restart: always
        command: webserver
        depends_on:
            - postgres
        environment:
            - LOAD_EX=n
            - EXECUTOR=Local
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
            # CKAN instance to write harvested packages
            - CKAN_API_KEY=625bafb3-42da-48a5-b9c2-c35c0e6085e1
            - CKAN_BASE_URL=http://nginx:8080
            - CKAN_VALID_USER_ID=admin
            - HARVESTER_APP_PATH=/app
            - AIRFLOW__CORE__DAGS_FOLDER=/app/automate-tasks/airflow/dags
            - AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT=180
            # The amount of parallelism as a setting to the executor. This defines
            # the max number of task instances that should run simultaneously
            # on this airflow installation
            - AIRFLOW__CORE__PARALLELISM=3
            # The number of task instances allowed to run concurrently by the scheduler
            - AIRFLOW__CORE__DAG_CONCURRENCY=2
            # if False all (or limited by other settings) the harvesters will run at start
            - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False
        ports:
            - "8081:8080"
        extra_hosts:
            # just if you have a local CKAN instance running in _nginx_ host in you local machine
            # export HOST_IP=`ip -4 addr show scope global dev docker0 | grep inet | awk '{print \$2}' | cut -d / -f 1`
            - "nginx:${HOST_IP}"
        healthcheck:
            test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
            interval: 30s
            timeout: 30s
            retries: 3
